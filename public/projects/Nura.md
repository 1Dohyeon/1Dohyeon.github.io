# Nura: RAG 기반 AI 문서 분석 및 질의응답 시스템

## 프로젝트 개요

> 프로젝트 정보
>
> - 프로젝트명: Nura
> - 목적: [NewLearn Note](https://1dohyeon.github.io/#/projects/newlearnnote)에 통합될 AI 문서 분석 기능의 독립 프로토타입 구축 및 RAG 파이프라인 검증
> - 개발 기간: 2025.12
> - 개발 인원: 1인 (개인 프로젝트)

### 왜 이 프로젝트를 시작했는가?

[NewLearn Note](https://1dohyeon.github.io/#/projects/newlearnnote)의 핵심 기능 중 하나는 사용자가 작성한 노트를 AI가 분석하고 질문에 답변하는 것입니다. 하지만 메인 프로젝트에 바로 AI 기능을 통합하기에는 다음과 같은 우려가 있었습니다:

- **기술적 불확실성**: RAG 파이프라인의 각 단계(문서 파싱, 청킹, 임베딩, 검색, 생성)를 처음 다뤄보는 것이라 어떤 문제가 생길지 예측하기 어려웠습니다.
- **성능 검증 필요**: 문서 크기에 따른 응답 속도, 청킹 전략에 따른 답변 정확도 등을 미리 테스트해야 했습니다.
- **독립적인 실험 환경**: 메인 프로젝트에 영향을 주지 않고 자유롭게 실험하고 싶었습니다.

이러한 이유로 Nura를 독립 프로젝트로 개발하여 RAG 파이프라인을 먼저 검증하고, 이후 [NewLearn Note](https://1dohyeon.github.io/#/projects/newlearnnote)에 안정적으로 통합하는 전략을 선택했습니다.

## 개발 내용

### 1. FastAPI 기반 RESTful API 서버 설계 및 구현

**프레임워크 선택:**
백엔드 프레임워크로 두 가지 옵션이 있었습니다:
- **Option A**: NestJS - 메인 프로젝트와 동일한 스택, 하지만 Python AI 라이브러리 연동 복잡
- **Option B**: FastAPI - Python 네이티브 지원, AI 라이브러리 생태계 활용 용이

**선택 이유:**
- **Python AI 생태계 활용**: LangChain, ChromaDB, OpenAI API 등이 모두 Python 기반
- **빠른 개발 속도**: 프로토타입 검증이 목적이므로 개발 속도 우선
- **비동기 처리 지원**: FastAPI의 네이티브 async/await로 문서 처리 성능 향상

**API 설계:**
- 문서 업로드, 질의응답, 문서 관리 등 RESTful 엔드포인트 구성
- Pydantic을 활용한 요청/응답 데이터 검증
- CORS 설정으로 Next.js 프론트엔드와 안전한 통신

### 2. RAG(Retrieval-Augmented Generation) 파이프라인 아키텍처 설계

**파이프라인 구조:**

사용자 문서 업로드
    ↓
파싱 (PDF/MD/TXT)
    ↓
청킹 (의미 단위 분할)
    ↓
임베딩 (벡터 변환)
    ↓
ChromaDB 저장
    ↓
사용자 질문 입력
    ↓
질문 임베딩
    ↓
유사도 검색 (Top-K)
    ↓
관련 문서 추출
    ↓
프롬프트 생성
    ↓
OpenAI API 호출
    ↓
답변 반환


**사용자 경험 설계:**
- PDF, Markdown, Text 파일을 드래그 앤 드롭으로 업로드
- 복잡한 검색 과정 없이 바로 질문할 수 있도록 UX 단순화

### 3. LangChain을 활용한 문서 처리 및 임베딩 생성

**LangChain 도입:**
- 문서 로더, 텍스트 스플리터, 임베딩 등 통합된 인터페이스 제공
- RetrievalQA 체인으로 RAG 파이프라인 간단히 구성
- 프롬프트 템플릿 관리 용이

**문서 처리 파이프라인:**
- PDF, Markdown, Text 파일 형식 자동 감지 및 파싱
- 문서 메타데이터 추출 및 저장
- 전처리된 문서를 벡터 임베딩으로 변환

### 4. ChromaDB 벡터 데이터베이스 통합 및 유사도 검색 구현

**ChromaDB 선택 이유:**
- 경량화되어 있고 Python 통합이 쉬움
- 로컬 개발 및 프로토타입 검증에 적합
- 벡터 검색 성능 우수

**벡터 검색 시스템:**
- 문서 청크를 임베딩하여 벡터로 변환 후 저장
- 사용자 질문도 임베딩하여 유사도 기반 검색
- Top-K 검색으로 가장 관련성 높은 문서 청크 추출

### 5. OpenAI GPT-4o-mini API 통합 및 프롬프트 엔지니어링

**프롬프트 전략:**
- **초기**: 단순히 "이 문서를 읽고 질문에 답해줘"
- **문제점**: 문서와 관련 없는 질문에도 문서 내용을 억지로 끼워 맞춰 답변
- **개선**: "주어진 문서와 관련된 질문이면 문서 내용을 우선 참고하고, 관련 없는 질문이면 AI의 일반 지식으로 유연하게 답변"
- **목표**: 문서 기반 답변과 일반 대화를 자연스럽게 전환할 수 있는 유연한 AI 어시스턴트 구현

**API 통합:**
- 검색된 문서 청크를 컨텍스트로 제공
- 시스템 프롬프트로 AI의 답변 스타일 정의
- 토큰 사용량 최적화

### 6. PDF 문서 파싱 및 청킹 알고리즘 최적화

**청킹 전략 개선:**
- **초기**: 고정 길이 청킹 (500자) → 문장이 중간에 잘리는 문제 발생
- **개선**: 문단/섹션 단위 청킹으로 의미 보존
- **최적화**: 청크 크기 조절 (너무 작으면 맥락 손실, 너무 크면 검색 정확도 하락)

**문서 파싱:**
- PDF 레이아웃 분석 및 텍스트 추출
- Markdown 구조화 (헤딩, 리스트 등) 보존
- 특수 문자 및 인코딩 처리

### 7. 비동기 문서 처리 및 성능 최적화

**비동기 처리 구현:**
- **문제**: 대용량 PDF 파일(100페이지 논문) 처리 시 약 30초 소요, 사용자 대기 발생
- **해결**: FastAPI의 BackgroundTasks 활용
  - 파일 업로드 즉시 응답 반환 (작업 ID 제공)
  - 백그라운드에서 문서 파싱 및 임베딩 진행
  - 상태 확인 API로 진행 상황 조회 가능

**에러 처리:**
- 비동기 작업 실패 시 사용자에게 알림
- 실패한 문서는 재시도 가능하도록 설계

**데이터 영속성:**
- GCS (Google Cloud Storage)를 활용한 문서 저장
- 서버 재시작이나 재배포 시에도 문서 보존
- [NewLearn Note](https://1dohyeon.github.io/#/projects/newlearnnote) 프로젝트와 통합 용이

## 프로젝트를 통해 배운 점

이 프로젝트를 통해 RAG 시스템의 작동 원리를 깊이 이해하고 실용적인 AI 서비스를 만드는 방법을 배웠습니다. 특히 문서 청킹 전략이 전체 시스템 성능에 큰 영향을 미친다는 점을 깨달았으며, 프롬프트 엔지니어링이 AI 시스템의 품질을 결정한다는 것을 경험했습니다. 

프로토타입 우선 접근 방식을 통해 메인 프로젝트에 바로 통합하지 않고 독립적으로 검증함으로써 실패 비용을 낮추고 빠르게 학습할 수 있었습니다. 또한 익숙한 NestJS 대신 프로젝트에 적합한 FastAPI를 선택하면서, 도구는 목적에 맞게 선택해야 한다는 교훈을 얻었습니다.

향후 Nura에서 검증한 RAG 파이프라인을 [NewLearn Note](https://1dohyeon.github.io/#/projects/newlearnnote)에 통합하여, Next.js 웹/Electron 데스크톱 앱에서 AI 어시스턴스 UI를 구현할 예정입니다.